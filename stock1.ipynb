{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Extract data (this is a placeholder, adapt to actual HTML structure)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdj Close\u001b[39m\u001b[38;5;124m'\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madj_close\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m     25\u001b[0m }\n\u001b[0;32m     27\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([data])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL for NSE stock data (replace with actual URL and parameters)\n",
    "url = \"https://www.nseindia.com/get-quotes/equity?symbol=ACC\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Parse HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Extract data (this is a placeholder, adapt to actual HTML structure)\n",
    "data = {\n",
    "    'Open': soup.find('span', {'id': 'open'}).text,\n",
    "    'High': soup.find('span', {'id': 'high'}).text,\n",
    "    'Low': soup.find('span', {'id': 'low'}).text,\n",
    "    'Close': soup.find('span', {'id': 'close'}).text,\n",
    "    'Adj Close': soup.find('span', {'id': 'adj_close'}).text,\n",
    "    'Volume': soup.find('span', {'id': 'volume'}).text,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([data])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Open         High          Low        Close  \\\n",
      "Date                                                                            \n",
      "2023-01-02 00:00:00+05:30  2345.364179  2372.037047  2343.708650  2369.185791   \n",
      "2023-01-03 00:00:00+05:30  2359.206430  2366.518491  2343.340844  2351.848389   \n",
      "2023-01-04 00:00:00+05:30  2351.802569  2355.527691  2312.253308  2316.438232   \n",
      "2023-01-05 00:00:00+05:30  2320.991026  2332.855853  2303.055845  2312.299316   \n",
      "2023-01-06 00:00:00+05:30  2323.888039  2343.478747  2316.208137  2333.315430   \n",
      "\n",
      "                            Volume  Dividends  Stock Splits  \n",
      "Date                                                         \n",
      "2023-01-02 00:00:00+05:30  2658087        0.0           0.0  \n",
      "2023-01-03 00:00:00+05:30  3829466        0.0           0.0  \n",
      "2023-01-04 00:00:00+05:30  4632445        0.0           0.0  \n",
      "2023-01-05 00:00:00+05:30  6818549        0.0           0.0  \n",
      "2023-01-06 00:00:00+05:30  3174798        0.0           0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 245 entries, 2023-01-02 00:00:00+05:30 to 2023-12-29 00:00:00+05:30\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Open          245 non-null    float64\n",
      " 1   High          245 non-null    float64\n",
      " 2   Low           245 non-null    float64\n",
      " 3   Close         245 non-null    float64\n",
      " 4   Volume        245 non-null    int64  \n",
      " 5   Dividends     245 non-null    float64\n",
      " 6   Stock Splits  245 non-null    float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 15.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch data\n",
    "ticker = 'RELIANCE.NS'  # Add '.NS' for NSE stocks on Yahoo Finance\n",
    "stock = yf.Ticker(ticker)\n",
    "df = stock.history(start='2023-01-01', end='2023-12-31')\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Symbol': 'ACC', 'Price': 'N/A', 'Open': 'N/A', 'High': 'N/A', 'Low': 'N/A', 'Close': 'N/A'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL for NSE stock data (replace with actual URL)\n",
    "url = \"https://www.nseindia.com/get-quotes/equity?symbol=ACC\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract data (adjust selectors as needed)\n",
    "    data = {\n",
    "        'Symbol': 'ACC',\n",
    "        'Price': soup.find('span', {'id': 'lastPrice'}).text if soup.find('span', {'id': 'lastPrice'}) else 'N/A',\n",
    "        'Open': soup.find('span', {'id': 'dayOpen'}).text if soup.find('span', {'id': 'dayOpen'}) else 'N/A',\n",
    "        'High': soup.find('span', {'id': 'dayHigh'}).text if soup.find('span', {'id': 'dayHigh'}) else 'N/A',\n",
    "        'Low': soup.find('span', {'id': 'dayLow'}).text if soup.find('span', {'id': 'dayLow'}) else 'N/A',\n",
    "        'Close': soup.find('span', {'id': 'dayClose'}).text if soup.find('span', {'id': 'dayClose'}) else 'N/A',\n",
    "    }\n",
    "\n",
    "    print(data)\n",
    "else:\n",
    "    print(\"Failed to retrieve data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
